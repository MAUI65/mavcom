{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mavlink Documentation and debugging\n",
    "> Mavlink Documentaion and debugging with wireshark and QGC\n",
    "\n",
    "[https://mavlink.io/en/mavgen_python/](https://mavlink.io/en/mavgen_python/)\n",
    "[https://www.ardusub.com/developers/pymavlink.html](https://www.ardusub.com/developers/pymavlink.html)\n",
    "\n",
    "https://mavlink.io/en/messages/common.html\n",
    "https://mavlink.io/en/messages/common.html#MAV_TYPE\n",
    "[Using MAVLink for custom applications](https://medium.com/@tonyjacob_/using-mavlink-for-custom-applications-466e1d632f84)\n",
    "[MavLink Tutorial for Absolute Dummies (Part â€“I)](https://storage.ning.com/topology/rest/1.0/file/get/3691077473?profile=original)\n",
    "[MAVLink Developer Guide](https://mavlink.io/en/)\n",
    "[Ardupilt MAVLink Basics](https://ardupilot.org/dev/docs/mavlink-basics.html)\n",
    "[ArduSub Pymavlink](https://www.ardusub.com/developers/pymavlink.html)\n",
    "[]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   # | default_exp mavlink.cam_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mavcom.logging\n",
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# skip_showdoc: true to avoid running cells when rendering docs, and \n",
    "# skip_exec: true to skip this notebook when running tests. \n",
    "# this should be a raw cell "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mavlink Routing***\n",
    "[https://ardupilot.org/dev/docs/mavlink-routing-in-ardupilot.html](https://ardupilot.org/dev/docs/mavlink-routing-in-ardupilot.html)\n",
    "Each message contains a System ID and Component ID field to specify where the message came from. In addition some messages (including SET_POSITION_TARGET_GLOBAL_INT) include target_system and target_component fields to allow specifying which system/component should execute the command.\n",
    "![](images/mavlink-routing.png){fig-align=\"center\"}\n",
    "\n",
    "[https://mavlink.io/en/guide/routing.html](https://mavlink.io/en/guide/routing.html) \n",
    "A MAVLINK network is made up of systems (vehicles, ground stations, antenna trackers, etc.), which may be composed from one or more components (autopilot, camera, servos, etc.).\n",
    "\n",
    "Each system has a network-unique system id, and each component has a system-unique component id that can be used for addressing/routing:\n",
    "\n",
    "The system id has a value between 1 and 255.\n",
    "The default autopilot system id is usually 1. Users should allocate unique increasing id values when adding new autopilots to a network.\n",
    "GCS systems and developer APIs typically use an ID at the top of the numeric range to reduce ID clashes (e.g. 255). Often their system ID is configurable to allow multi-GCS systems.\n",
    "The component id is allocated by type and number from MAV_COMPONENT.\n",
    "Messages can be intended for all systems, specific systems, all components in a system, or specific components within a system. The protocol defines two 8-bit fields that can (optionally) be specified in the message payload to indicate where the message should be sent/routed. If the ids are omitted or set to zero then the message is considered a broadcast (intended for all systems/components).\n",
    "\n",
    "target_system: System that should execute the command\n",
    "target_component: Component that should execute the command (requires target_system).\n",
    "MAVLink components are expected to process messages that have a matching system/component id and broadcast messages. They are expected to route/resend messages that are intended for other (or all) recipients to other active channels (i.e. MAVLink systems may be connected across different transports, connected by a MAVLink system that routes the messages). Broadcast messages are forwarded to all channels that haven't seen the message. Addressed messages are resent on a new channel iff the system has previously seen a message from the target on that channel (messages are not resent if the addressee is not known or is on the original/incoming channel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mavlink Camera Control via mavproxy serial port and UDP\n",
    "*** First Run Mavproxy***\n",
    "```sh\n",
    "mavproxy.py --master udpin:localhost:14445 --out udpout:localhost:14550\n",
    "mavproxy.py --master=/dev/ttyACM1 --baudrate 57600 --out udpout:localhost:14445\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mavlink Camera Control via mavproxy serial port and UDP\n",
    "The camera control messages are sent to the camera server via mavproxy. The camera server is running on the companion computer and the manager on the GCS PC. We connect via UDP and wait for the camera heartbeat. Then start and stop the cam_1 (component 22)  streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |30.150| mavcom.MAVCom      | mavcom.py :378 | Thread-77  | MainProces | MAVLink Mav2: True, source_system: 111\u001b[0m\n",
      "\u001b[32mINFO |30.251| mavcom.MAVCom      | mavcom.py :378 | Thread-78  | MainProces | MAVLink Mav2: True, source_system: 222\u001b[0m\n",
      "\u001b[32mINFO |30.253| mavcom.CameraClien | component.:117 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\u001b[0m\n",
      "\u001b[32mINFO |30.257| mavcom.GSTCamera   | gst_cam.py:351 | MainThread | MainProces | GSTCamera Started\u001b[0m\n",
      "\u001b[32mINFO |30.269| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_1  sync=false t. ! interpipesink name=cam_0 \u001b[0m\n",
      "\u001b[37mDEBUG|30.269| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|30.270| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |30.272| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\u001b[0m\n",
      "\u001b[37mDEBUG|30.273| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|30.273| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |30.274| mavcom.GSTCamera   | gst_cam.py:654 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\u001b[0m\n",
      "\u001b[37mDEBUG|30.374| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\u001b[0m\n",
      "\u001b[32mINFO |30.375| mavcom.GSTCamera   | gst_cam.py:668 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\u001b[0m\n",
      "\u001b[32mINFO |30.378| mavcom.GSTCamera   | gst_cam.py:351 | MainThread | MainProces | GSTCamera Started\u001b[0m\n",
      "\u001b[32mINFO |30.390| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Left\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_1  sync=false t. ! interpipesink name=cam_1 \u001b[0m\n",
      "\u001b[32mINFO |30.393| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_1 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5001 sync=true\u001b[0m\n",
      "\u001b[32mINFO |30.394| mavcom.GSTCamera   | gst_cam.py:654 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe                        \n",
      "John Doe                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |30.495| mavcom.GSTCamera   | gst_cam.py:668 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5001\u001b[0m\n",
      "\u001b[32mINFO |30.496| mavcom.CameraServe | component.:117 | MainThread | MainProces | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\u001b[0m\n",
      "\u001b[32mINFO |30.498| mavcom.CameraServe | component.:117 | MainThread | MainProces | Component Started self.source_component = 23, self.mav_type = 30, self.source_system = 222\u001b[0m\n",
      "\u001b[32mINFO |30.600| mavcom.GSTCamera   | gst_cam.py:662 | Thread-84  | MainProces | Video streaming \"gstreamer_udpsink\" resumed on port 5000\u001b[0m\n",
      "\u001b[32mINFO |30.601| mavcom.CameraServe | camera_ser:338 | Thread-84  | MainProces | Started video streaming: streamId = 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heartbeat ret = (222, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |32.703| mavcom.GSTCamera   | gst_cam.py:668 | Thread-84  | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\u001b[0m\n",
      "\u001b[32mINFO |33.407| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |33.409| mavcom.GSTCamera   | gst_cam.py:513 | MainThread | MainProces | GSTCamera closed\u001b[0m\n",
      "\u001b[32mINFO |33.580| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |33.582| mavcom.GSTCamera   | gst_cam.py:707 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[32mINFO |33.583| mavcom.CameraServe | component.:388 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n",
      "\u001b[32mINFO |33.690| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |33.691| mavcom.GSTCamera   | gst_cam.py:513 | MainThread | MainProces | GSTCamera closed\u001b[0m\n",
      "\u001b[32mINFO |33.801| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |33.803| mavcom.GSTCamera   | gst_cam.py:707 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[32mINFO |33.804| mavcom.CameraServe | component.:388 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n",
      "\u001b[32mINFO |33.805| mavcom.MAVCom      | mavcom.py :427 | MainThread | MainProces | MAVCom  closed\u001b[0m\n",
      "\u001b[32mINFO |34.503| mavcom.CameraClien | component.:388 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n",
      "\u001b[32mINFO |34.505| mavcom.MAVCom      | mavcom.py :427 | MainThread | MainProces | MAVCom  closed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "import time\n",
    "\n",
    "from fastcore.test import *\n",
    "from mavcom.mavlink import CameraClient, CameraServer, MAVCom, mavlink\n",
    "from mavcom.cameras.gst_cam import GSTCamera\n",
    "from mavcom.utils import helpers\n",
    "from mavcom.utils.general import boot_time_str, toml_load, config_dir\n",
    "\n",
    "\n",
    "async def main():\n",
    "    with MAVCom(\"udpin:localhost:14445\", source_system=111, ) as gcs_mavlink:   # ground control station mavlink\n",
    "        with MAVCom(\"udpout:localhost:14445\", source_system=222, ) as drone_mavlink: # drone mavlink\n",
    "            # connect to the cameras manager\n",
    "            gcs_cam: CameraClient = gcs_mavlink.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n",
    "            \n",
    "            # add UAV cameras\n",
    "            cam_1 = GSTCamera(camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=10)\n",
    "            cam_2 = GSTCamera(camera_dict=toml_load(config_dir() / \"test_cam_1.toml\"))\n",
    "\n",
    "            # connect cameras to mavlink\n",
    "            drone_mavlink.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=22, camera=cam_1,))\n",
    "            drone_mavlink.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=23, camera=cam_2))\n",
    "            \n",
    "            # wait for heartbeat signal from the drone\n",
    "            ret = await gcs_cam.wait_heartbeat(target_system=222, target_component=22, timeout=1)\n",
    "            print(f\"Heartbeat {ret = }\")\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            await gcs_cam.video_start_streaming(222, 22, )\n",
    "            time.sleep(2)\n",
    "            await gcs_cam.video_stop_streaming(222, 22, )\n",
    "            \n",
    "await main()  \n",
    "            # client.master.wait_heartbeat()\n",
    "            \n",
    "        #     client.trigger_camera(2)\n",
    "        #     client.trigger_camera(2)\n",
    "        # \n",
    "        # \n",
    "        # print(f\"client.num_commands_sent: {client.num_commands_sent}\")\n",
    "        # print(f\"server.num_commands_received: {server.num_commands_received}\")\n",
    "        # print(f\"client.num_acks_received: {client.num_acks_received}\")\n",
    "        # \n",
    "        # print(f\"server msgs: {server.message_cnts}\")\n",
    "        # print(f\"client msgs: {client.message_cnts}\")\n",
    "        # \n",
    "        # test_eq(client.num_commands_sent, server.num_commands_received)\n",
    "        # test_eq(client.num_acks_received, server.num_commands_received)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging with wireshark\n",
    "see [Parsing MAVLink in Wireshark](https://mavlink.io/en/guide/wireshark.html)\n",
    "Instasll wireshark  \n",
    "see [How to install and use wireshark- on ubuntu](https://www.geeksforgeeks.org/how-to-install-and-use-wireshark-on-ubuntu-linux/)\n",
    "```sh\n",
    "sudo apt-get install wireshark\n",
    "sudo apt update\n",
    "sudo apt install wireshark\n",
    "wireshark\n",
    "```\n",
    "If you face any error during installation or running Wireshark like `Wireshark xdg_runtime_dir not set` then open the terminal and run this command and click YES to the message box\n",
    "```sh\n",
    "sudo dpkg-reconfigure wireshark-common\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The above can be debugged with wireshark using the ***filter***\n",
    "\n",
    "```sh\n",
    "mavlink_proto.sysid!=255 && not icmp\n",
    "mavlink_proto.sysid!=255 && mavlink_proto.sysid!=1 && not icmp\n",
    "```\n",
    "\n",
    "![](images/wireshark_debug.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Wireshark on Ubuntu***\n",
    "see [Parsing MAVLink in Wireshark](https://mavlink.io/en/guide/wireshark.html)\n",
    "\n",
    "Wireshark has implemented Privilege Separation which means that the Wireshark GUI (or the tshark CLI) can run as a normal user while the dumpcap capture utility runs as root. This can be achieved by installing dumpcap setuid root. The advantage of this solution is that while dumpcap is run as root the vast majority of Wireshark's code is run as a normal user (where it can do much less damage).\n",
    "[https://wikileaks.org/ciav7p1/cms/page_16384719.html](https://wikileaks.org/ciav7p1/cms/page_16384719.html)\n",
    "- Install Wireshark\n",
    "`sudo apt-get install wireshark`\n",
    "- Create a wireshark group\n",
    "`sudo groupadd wireshark`\n",
    "- Add your username to the wireshark group\n",
    "`sudo usermod -a -G wireshark YOUR_USERNAME`\n",
    "- Change the group ownership of the file dumpcap to wireshark\n",
    "`sudo chgrp wireshark /usr/bin/dumpcap`\n",
    "- Chage the mode of the file dumpcap to allow execution by the group wireshark\n",
    "`sudo chmod 750 /usr/bin/dumpcap`\n",
    "- Grant capabilities with setcap\n",
    "`sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap`\n",
    "- Verify the change\n",
    "`sudo getcap /usr/bin/dumpcap`\n",
    "- Reboot\n",
    "- `sudo reboot now`\n",
    "\n",
    "***Also see ****\n",
    "[https://wiki.wireshark.org/CaptureSetup/CapturePrivileges](https://wiki.wireshark.org/CaptureSetup/CapturePrivileges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Note*** \n",
    "The last few lines of the plugin file specify the ports to be monitored.\n",
    "> `-- bind protocol dissector to port 14550 and 14580`\n",
    ">>`local udp_dissector_table = DissectorTable.get(\"udp.port\")`\n",
    "`udp_dissector_table:add(14415, mavlink_proto)`\n",
    "`udp_dissector_table:add(14425, mavlink_proto)`\n",
    "`udp_dissector_table:add(14435, mavlink_proto)`\n",
    "`udp_dissector_table:add(14445, mavlink_proto)`\n",
    "`udp_dissector_table:add(14550, mavlink_proto)`\n",
    "`udp_dissector_table:add(14580, mavlink_proto)`\n",
    "`udp_dissector_table:add(18570, mavlink_proto)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QGC can also be used to debug the communication\n",
    "\n",
    "![](images/QGC_mavlink_inspect.png)\n",
    "\n",
    "Enable mavlink fowarding in QGC to localhost:14445\n",
    "\n",
    "![](images/QGC_mav_settings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial Port Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Connection using a serial crossover cable or via pixhawk telemetry ports\n",
    "![](../tutorials/images/serial_crossover.jpeg)  \n",
    "Telemetry 2 port on pixhawk is connected to the USB port on the companion computer using a serial crossover cable.\n",
    "1. (red) VCC +5V\n",
    "2. (?) TX (OUT) +3.3V\n",
    "3. (?) RX (IN) +3.3V\n",
    "4. (?) CTS +3.3V\n",
    "5. (?) RTS +3.3V\n",
    "6. (?) GND GND`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the correct serial ports\n",
    "Check that  if you are a member of that group: \"dialout\" group. \n",
    "\n",
    "```sh \n",
    "groups ${USER}\n",
    "```\n",
    "\n",
    "If not, add yourself to it and reboot or logout and login again.\n",
    "\n",
    "```sh\n",
    "sudo usermod -a -G dialout $USER\n",
    "sudo reboot now\n",
    "```\n",
    "Cutecom is a GUI serial terminal program that can be used to test the serial ports. \n",
    "```sh\n",
    "sudo apt-get install cutecom lrzsz\n",
    "```\n",
    "Run Cutecom and select the correct serial port and baud rate. Note that the status bar showing Ardupilot Pihawk4, also check that it might be using 57600 baud rate.\n",
    "```sh\n",
    "cutecom\n",
    "```\n",
    "![](images/cutecom.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PX4 SITL  \n",
    "see [PX4 SITL Gazebo Simulation](https://docs.px4.io/main/en/sim_gazebo_gz/)\n",
    "\n",
    "in the PX4 directory run\n",
    "`make px4_sitl gz_x500`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Run Mavproxy***\n",
    "`mavproxy.py --master udpin:localhost:14445 --out udpout:localhost:14550`\n",
    "`mavproxy.py --master=/dev/ttyACM1 --baudrate 57600 --out udpout:localhost:14445`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mavlink/MAVSDK/issues/1803\n",
    "\n",
    "So I managed to change OpenHD in this regard.\n",
    "No idea why I had such a hard time wrapping my head around, but now it works the following:\n",
    "OpenHD binds port 127.0.0.1:14551 and listens on 127.0.0.1:14550\n",
    "AND\n",
    "instead of using sendto() with a unbound port (which then in turn means the sender port can be anything) messages are sent with sendto() from the bound port (the same that is used for listening).\n",
    "\n",
    "So messages from OpenHD to mavsdk go the following:\n",
    "OpenHD (out) via 127:0:0:1:14551 sent to 127:0:0:0:1:14550\n",
    "\n",
    "So when mavsdk receives the first message, the sender address::port is 127:0:0:1:14551 and mavsdk can send the messages back to 127:0:0:1:14551.\n",
    "\n",
    "https://julianoes.com/\n",
    "The ports are not symmetrical! QGC listens on local port 14550 and sends UDP packets back to wherever messages came from.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
